{"cells":[{"cell_type":"markdown","source":["# **Checkpoint** **save**"],"metadata":{"id":"MbUEZDu2H5mr"},"id":"MbUEZDu2H5mr"},{"cell_type":"code","execution_count":null,"id":"49ceee3f","metadata":{"id":"49ceee3f"},"outputs":[],"source":["import tensorflow as tf\n","checkpoint_filepath = '/tmp/checkpoint'\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=True,\n","    monitor='val_acc',\n","    mode='max',\n","    save_best_only=True)"]},{"cell_type":"markdown","source":["# **Model Setup and Data Exploration**"],"metadata":{"id":"5K1XqmGKImOT"},"id":"5K1XqmGKImOT"},{"cell_type":"code","execution_count":null,"id":"caf87379","metadata":{"id":"caf87379","outputId":"24e96f2a-07c3-4a52-a7da-02cd1d607773"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 5998 images belonging to 10 classes.\n","Found 1260 images belonging to 10 classes.\n","Number of folders in train directory: 10\n","Number of images per folder in train directory:\n","0: 600 images\n","1: 600 images\n","2: 600 images\n","3: 600 images\n","4: 600 images\n","5: 600 images\n","6: 600 images\n","7: 600 images\n","8: 600 images\n","9: 598 images\n","\n","Number of folders in valid directory: 10\n","Number of images per folder in valid directory:\n","0: 126 images\n","1: 126 images\n","2: 126 images\n","3: 126 images\n","4: 126 images\n","5: 126 images\n","6: 126 images\n","7: 126 images\n","8: 126 images\n","9: 126 images\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import backend as K\n","from os import listdir\n","from os.path import isdir, join\n","\n","def count_folders_and_images(directory_path):\n","    folders_count = 0\n","    images_per_folder = {}\n","\n","    for folder_name in listdir(directory_path):\n","        folder_path = join(directory_path, folder_name)\n","        if isdir(folder_path):\n","            folders_count += 1\n","            images_count = len(listdir(folder_path))\n","            images_per_folder[folder_name] = images_count\n","\n","    return folders_count, images_per_folder\n","\n","# Load and preprocess the data\n","train_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_directory = './path_to_new_train_directory'\n","valid_directory = './path_to_new_valid_directory'\n","\n","training_set = train_datagen.flow_from_directory(train_directory, target_size=(64, 64), batch_size=32, class_mode='sparse', color_mode='grayscale')\n","test_set = test_datagen.flow_from_directory(valid_directory, target_size=(64, 64), batch_size=32, class_mode='sparse', color_mode='grayscale')\n","\n","# Count folders and images in train and valid directories\n","train_folders_count, train_images_per_folder = count_folders_and_images(train_directory)\n","valid_folders_count, valid_images_per_folder = count_folders_and_images(valid_directory)\n","\n","print(\"Number of folders in train directory:\", train_folders_count)\n","print(\"Number of images per folder in train directory:\")\n","for folder_name, images_count in train_images_per_folder.items():\n","    print(f\"{folder_name}: {images_count} images\")\n","\n","print(\"\\nNumber of folders in valid directory:\", valid_folders_count)\n","print(\"Number of images per folder in valid directory:\")\n","for folder_name, images_count in valid_images_per_folder.items():\n","    print(f\"{folder_name}: {images_count} images\")\n"]},{"cell_type":"code","execution_count":null,"id":"6b11a0f5","metadata":{"id":"6b11a0f5","outputId":"f2f9fbb2-e978-45c0-d45d-9fcd8b39839a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/200\n","188/188 [==============================] - 168s 863ms/step - loss: 2.7750 - accuracy: 0.1039 - val_loss: 2.3865 - val_accuracy: 0.1040 - lr: 0.0010\n","Accuracy: 0.1039 | Loss: 2.7750 | Val Accuracy: 0.1040 | Val Loss: 2.3865\n","Epoch 2/200\n","188/188 [==============================] - 161s 856ms/step - loss: 2.5178 - accuracy: 0.1087 - val_loss: 2.4365 - val_accuracy: 0.1198 - lr: 0.0010\n","Accuracy: 0.1087 | Loss: 2.5178 | Val Accuracy: 0.1198 | Val Loss: 2.4365\n","Epoch 3/200\n","188/188 [==============================] - 172s 916ms/step - loss: 2.4174 - accuracy: 0.1149 - val_loss: 2.3939 - val_accuracy: 0.1365 - lr: 0.0010\n","Accuracy: 0.1149 | Loss: 2.4174 | Val Accuracy: 0.1365 | Val Loss: 2.3939\n","Epoch 4/200\n","188/188 [==============================] - 185s 985ms/step - loss: 2.3954 - accuracy: 0.1150 - val_loss: 2.3874 - val_accuracy: 0.1135 - lr: 0.0010\n","Accuracy: 0.1150 | Loss: 2.3954 | Val Accuracy: 0.1135 | Val Loss: 2.3874\n","Epoch 5/200\n","188/188 [==============================] - 171s 908ms/step - loss: 2.3712 - accuracy: 0.1214 - val_loss: 2.3638 - val_accuracy: 0.1238 - lr: 0.0010\n","Accuracy: 0.1214 | Loss: 2.3712 | Val Accuracy: 0.1238 | Val Loss: 2.3638\n","Epoch 6/200\n","188/188 [==============================] - 165s 880ms/step - loss: 2.3786 - accuracy: 0.1244 - val_loss: 2.3567 - val_accuracy: 0.1278 - lr: 0.0010\n","Accuracy: 0.1244 | Loss: 2.3786 | Val Accuracy: 0.1278 | Val Loss: 2.3567\n","Epoch 7/200\n","188/188 [==============================] - 159s 848ms/step - loss: 2.3521 - accuracy: 0.1234 - val_loss: 2.3546 - val_accuracy: 0.1333 - lr: 0.0010\n","Accuracy: 0.1234 | Loss: 2.3521 | Val Accuracy: 0.1333 | Val Loss: 2.3546\n","Epoch 8/200\n","188/188 [==============================] - 173s 922ms/step - loss: 2.3565 - accuracy: 0.1255 - val_loss: 2.3098 - val_accuracy: 0.1341 - lr: 0.0010\n","Accuracy: 0.1255 | Loss: 2.3565 | Val Accuracy: 0.1341 | Val Loss: 2.3098\n","Epoch 9/200\n","188/188 [==============================] - 209s 1s/step - loss: 2.3477 - accuracy: 0.1289 - val_loss: 2.3854 - val_accuracy: 0.1079 - lr: 0.0010\n","Accuracy: 0.1289 | Loss: 2.3477 | Val Accuracy: 0.1079 | Val Loss: 2.3854\n","Epoch 10/200\n","188/188 [==============================] - 209s 1s/step - loss: 2.3173 - accuracy: 0.1477 - val_loss: 2.2752 - val_accuracy: 0.1381 - lr: 0.0010\n","Accuracy: 0.1477 | Loss: 2.3173 | Val Accuracy: 0.1381 | Val Loss: 2.2752\n","Epoch 11/200\n","188/188 [==============================] - 192s 1s/step - loss: 2.2724 - accuracy: 0.1564 - val_loss: 2.2474 - val_accuracy: 0.1667 - lr: 0.0010\n","Accuracy: 0.1564 | Loss: 2.2724 | Val Accuracy: 0.1667 | Val Loss: 2.2474\n","Epoch 12/200\n","188/188 [==============================] - 171s 911ms/step - loss: 2.1953 - accuracy: 0.1831 - val_loss: 2.1695 - val_accuracy: 0.2421 - lr: 0.0010\n","Accuracy: 0.1831 | Loss: 2.1953 | Val Accuracy: 0.2421 | Val Loss: 2.1695\n","Epoch 13/200\n","188/188 [==============================] - 162s 859ms/step - loss: 2.0882 - accuracy: 0.2241 - val_loss: 2.1712 - val_accuracy: 0.2484 - lr: 0.0010\n","Accuracy: 0.2241 | Loss: 2.0882 | Val Accuracy: 0.2484 | Val Loss: 2.1712\n","Epoch 14/200\n","188/188 [==============================] - 176s 936ms/step - loss: 1.9287 - accuracy: 0.2714 - val_loss: 2.1416 - val_accuracy: 0.2667 - lr: 0.0010\n","Accuracy: 0.2714 | Loss: 1.9287 | Val Accuracy: 0.2667 | Val Loss: 2.1416\n","Epoch 15/200\n","188/188 [==============================] - 170s 904ms/step - loss: 1.7904 - accuracy: 0.3101 - val_loss: 1.8497 - val_accuracy: 0.2802 - lr: 0.0010\n","Accuracy: 0.3101 | Loss: 1.7904 | Val Accuracy: 0.2802 | Val Loss: 1.8497\n","Epoch 16/200\n","188/188 [==============================] - 164s 873ms/step - loss: 1.7107 - accuracy: 0.3219 - val_loss: 1.5547 - val_accuracy: 0.3905 - lr: 0.0010\n","Accuracy: 0.3219 | Loss: 1.7107 | Val Accuracy: 0.3905 | Val Loss: 1.5547\n","Epoch 17/200\n","188/188 [==============================] - 160s 850ms/step - loss: 1.6024 - accuracy: 0.3640 - val_loss: 1.4282 - val_accuracy: 0.4254 - lr: 0.0010\n","Accuracy: 0.3640 | Loss: 1.6024 | Val Accuracy: 0.4254 | Val Loss: 1.4282\n","Epoch 18/200\n","188/188 [==============================] - 162s 860ms/step - loss: 1.5652 - accuracy: 0.3841 - val_loss: 1.9668 - val_accuracy: 0.3087 - lr: 0.0010\n","Accuracy: 0.3841 | Loss: 1.5652 | Val Accuracy: 0.3087 | Val Loss: 1.9668\n","Epoch 19/200\n","188/188 [==============================] - 162s 862ms/step - loss: 1.5144 - accuracy: 0.4018 - val_loss: 1.3980 - val_accuracy: 0.4595 - lr: 0.0010\n","Accuracy: 0.4018 | Loss: 1.5144 | Val Accuracy: 0.4595 | Val Loss: 1.3980\n","Epoch 20/200\n","188/188 [==============================] - 159s 848ms/step - loss: 1.4497 - accuracy: 0.4363 - val_loss: 1.2860 - val_accuracy: 0.5175 - lr: 0.0010\n","Accuracy: 0.4363 | Loss: 1.4497 | Val Accuracy: 0.5175 | Val Loss: 1.2860\n","Epoch 21/200\n","188/188 [==============================] - 204s 1s/step - loss: 1.3856 - accuracy: 0.4652 - val_loss: 1.2123 - val_accuracy: 0.5008 - lr: 0.0010\n","Accuracy: 0.4652 | Loss: 1.3856 | Val Accuracy: 0.5008 | Val Loss: 1.2123\n","Epoch 22/200\n","188/188 [==============================] - 184s 979ms/step - loss: 1.3571 - accuracy: 0.4635 - val_loss: 1.1817 - val_accuracy: 0.5270 - lr: 0.0010\n","Accuracy: 0.4635 | Loss: 1.3571 | Val Accuracy: 0.5270 | Val Loss: 1.1817\n","Epoch 23/200\n","188/188 [==============================] - 185s 985ms/step - loss: 1.3260 - accuracy: 0.4855 - val_loss: 1.0162 - val_accuracy: 0.5698 - lr: 0.0010\n","Accuracy: 0.4855 | Loss: 1.3260 | Val Accuracy: 0.5698 | Val Loss: 1.0162\n","Epoch 24/200\n","188/188 [==============================] - 175s 929ms/step - loss: 1.2843 - accuracy: 0.5023 - val_loss: 1.0147 - val_accuracy: 0.6016 - lr: 0.0010\n","Accuracy: 0.5023 | Loss: 1.2843 | Val Accuracy: 0.6016 | Val Loss: 1.0147\n","Epoch 25/200\n","188/188 [==============================] - 181s 959ms/step - loss: 1.2705 - accuracy: 0.5082 - val_loss: 0.9538 - val_accuracy: 0.6111 - lr: 0.0010\n","Accuracy: 0.5082 | Loss: 1.2705 | Val Accuracy: 0.6111 | Val Loss: 0.9538\n","Epoch 26/200\n","188/188 [==============================] - 183s 972ms/step - loss: 1.2080 - accuracy: 0.5402 - val_loss: 0.9019 - val_accuracy: 0.6516 - lr: 0.0010\n","Accuracy: 0.5402 | Loss: 1.2080 | Val Accuracy: 0.6516 | Val Loss: 0.9019\n","Epoch 27/200\n","188/188 [==============================] - 172s 914ms/step - loss: 1.1995 - accuracy: 0.5363 - val_loss: 0.9287 - val_accuracy: 0.6238 - lr: 0.0010\n","Accuracy: 0.5363 | Loss: 1.1995 | Val Accuracy: 0.6238 | Val Loss: 0.9287\n","Epoch 28/200\n","188/188 [==============================] - 162s 861ms/step - loss: 1.1750 - accuracy: 0.5463 - val_loss: 0.8908 - val_accuracy: 0.6341 - lr: 0.0010\n","Accuracy: 0.5463 | Loss: 1.1750 | Val Accuracy: 0.6341 | Val Loss: 0.8908\n","Epoch 29/200\n","188/188 [==============================] - 176s 938ms/step - loss: 1.1590 - accuracy: 0.5670 - val_loss: 0.7739 - val_accuracy: 0.6841 - lr: 0.0010\n","Accuracy: 0.5670 | Loss: 1.1590 | Val Accuracy: 0.6841 | Val Loss: 0.7739\n","Epoch 30/200\n","188/188 [==============================] - 184s 978ms/step - loss: 1.0926 - accuracy: 0.5844 - val_loss: 0.7804 - val_accuracy: 0.6778 - lr: 0.0010\n","Accuracy: 0.5844 | Loss: 1.0926 | Val Accuracy: 0.6778 | Val Loss: 0.7804\n","Epoch 31/200\n","188/188 [==============================] - 176s 935ms/step - loss: 1.0813 - accuracy: 0.5909 - val_loss: 0.8397 - val_accuracy: 0.6849 - lr: 0.0010\n","Accuracy: 0.5909 | Loss: 1.0813 | Val Accuracy: 0.6849 | Val Loss: 0.8397\n","Epoch 32/200\n","188/188 [==============================] - 167s 888ms/step - loss: 1.0637 - accuracy: 0.6032 - val_loss: 0.7542 - val_accuracy: 0.6897 - lr: 0.0010\n","Accuracy: 0.6032 | Loss: 1.0637 | Val Accuracy: 0.6897 | Val Loss: 0.7542\n","Epoch 33/200\n","188/188 [==============================] - 192s 1s/step - loss: 1.0117 - accuracy: 0.6155 - val_loss: 0.7227 - val_accuracy: 0.6889 - lr: 0.0010\n","Accuracy: 0.6155 | Loss: 1.0117 | Val Accuracy: 0.6889 | Val Loss: 0.7227\n","Epoch 34/200\n","188/188 [==============================] - 187s 993ms/step - loss: 0.9865 - accuracy: 0.6227 - val_loss: 0.8671 - val_accuracy: 0.6405 - lr: 0.0010\n","Accuracy: 0.6227 | Loss: 0.9865 | Val Accuracy: 0.6405 | Val Loss: 0.8671\n","Epoch 35/200\n","188/188 [==============================] - 186s 989ms/step - loss: 0.9552 - accuracy: 0.6352 - val_loss: 0.6088 - val_accuracy: 0.7373 - lr: 0.0010\n","Accuracy: 0.6352 | Loss: 0.9552 | Val Accuracy: 0.7373 | Val Loss: 0.6088\n","Epoch 36/200\n"]},{"name":"stdout","output_type":"stream","text":["188/188 [==============================] - 185s 983ms/step - loss: 0.9326 - accuracy: 0.6442 - val_loss: 0.5988 - val_accuracy: 0.7389 - lr: 0.0010\n","Accuracy: 0.6442 | Loss: 0.9326 | Val Accuracy: 0.7389 | Val Loss: 0.5988\n","Epoch 37/200\n","188/188 [==============================] - 186s 987ms/step - loss: 0.9356 - accuracy: 0.6439 - val_loss: 0.5681 - val_accuracy: 0.7746 - lr: 0.0010\n","Accuracy: 0.6439 | Loss: 0.9356 | Val Accuracy: 0.7746 | Val Loss: 0.5681\n","Epoch 38/200\n","188/188 [==============================] - 177s 942ms/step - loss: 0.8886 - accuracy: 0.6687 - val_loss: 0.5949 - val_accuracy: 0.7540 - lr: 0.0010\n","Accuracy: 0.6687 | Loss: 0.8886 | Val Accuracy: 0.7540 | Val Loss: 0.5949\n","Epoch 39/200\n","188/188 [==============================] - 169s 900ms/step - loss: 0.9051 - accuracy: 0.6642 - val_loss: 0.6080 - val_accuracy: 0.7365 - lr: 0.0010\n","Accuracy: 0.6642 | Loss: 0.9051 | Val Accuracy: 0.7365 | Val Loss: 0.6080\n","Epoch 40/200\n","188/188 [==============================] - 170s 906ms/step - loss: 0.8889 - accuracy: 0.6631 - val_loss: 0.5557 - val_accuracy: 0.7611 - lr: 0.0010\n","Accuracy: 0.6631 | Loss: 0.8889 | Val Accuracy: 0.7611 | Val Loss: 0.5557\n","Epoch 41/200\n","188/188 [==============================] - 170s 904ms/step - loss: 0.8718 - accuracy: 0.6684 - val_loss: 0.5645 - val_accuracy: 0.7754 - lr: 0.0010\n","Accuracy: 0.6684 | Loss: 0.8718 | Val Accuracy: 0.7754 | Val Loss: 0.5645\n","Epoch 42/200\n","188/188 [==============================] - 171s 912ms/step - loss: 0.8674 - accuracy: 0.6747 - val_loss: 0.5909 - val_accuracy: 0.7460 - lr: 0.0010\n","Accuracy: 0.6747 | Loss: 0.8674 | Val Accuracy: 0.7460 | Val Loss: 0.5909\n","Epoch 43/200\n","188/188 [==============================] - 184s 976ms/step - loss: 0.8396 - accuracy: 0.6834 - val_loss: 0.5218 - val_accuracy: 0.7841 - lr: 0.0010\n","Accuracy: 0.6834 | Loss: 0.8396 | Val Accuracy: 0.7841 | Val Loss: 0.5218\n","Epoch 44/200\n","188/188 [==============================] - 180s 959ms/step - loss: 0.7959 - accuracy: 0.6971 - val_loss: 0.4945 - val_accuracy: 0.7968 - lr: 0.0010\n","Accuracy: 0.6971 | Loss: 0.7959 | Val Accuracy: 0.7968 | Val Loss: 0.4945\n","Epoch 45/200\n","188/188 [==============================] - 177s 941ms/step - loss: 0.8161 - accuracy: 0.6966 - val_loss: 0.4756 - val_accuracy: 0.7968 - lr: 0.0010\n","Accuracy: 0.6966 | Loss: 0.8161 | Val Accuracy: 0.7968 | Val Loss: 0.4756\n","Epoch 46/200\n","188/188 [==============================] - 185s 982ms/step - loss: 0.7973 - accuracy: 0.6951 - val_loss: 0.5017 - val_accuracy: 0.7921 - lr: 0.0010\n","Accuracy: 0.6951 | Loss: 0.7973 | Val Accuracy: 0.7921 | Val Loss: 0.5017\n","Epoch 47/200\n","188/188 [==============================] - 189s 1s/step - loss: 0.7734 - accuracy: 0.7111 - val_loss: 0.5273 - val_accuracy: 0.7683 - lr: 0.0010\n","Accuracy: 0.7111 | Loss: 0.7734 | Val Accuracy: 0.7683 | Val Loss: 0.5273\n","Epoch 48/200\n","188/188 [==============================] - 165s 875ms/step - loss: 0.7599 - accuracy: 0.7157 - val_loss: 0.4680 - val_accuracy: 0.7968 - lr: 0.0010\n","Accuracy: 0.7157 | Loss: 0.7599 | Val Accuracy: 0.7968 | Val Loss: 0.4680\n","Epoch 49/200\n","188/188 [==============================] - 183s 972ms/step - loss: 0.7513 - accuracy: 0.7169 - val_loss: 0.4753 - val_accuracy: 0.7873 - lr: 0.0010\n","Accuracy: 0.7169 | Loss: 0.7513 | Val Accuracy: 0.7873 | Val Loss: 0.4753\n","Epoch 50/200\n","188/188 [==============================] - 184s 981ms/step - loss: 0.7546 - accuracy: 0.7184 - val_loss: 0.4787 - val_accuracy: 0.7952 - lr: 0.0010\n","Accuracy: 0.7184 | Loss: 0.7546 | Val Accuracy: 0.7952 | Val Loss: 0.4787\n","Epoch 51/200\n","188/188 [==============================] - 186s 987ms/step - loss: 0.7311 - accuracy: 0.7277 - val_loss: 0.5567 - val_accuracy: 0.7762 - lr: 0.0010\n","Accuracy: 0.7277 | Loss: 0.7311 | Val Accuracy: 0.7762 | Val Loss: 0.5567\n","Epoch 52/200\n","188/188 [==============================] - 181s 961ms/step - loss: 0.7644 - accuracy: 0.7109 - val_loss: 0.4628 - val_accuracy: 0.8063 - lr: 0.0010\n","Accuracy: 0.7109 | Loss: 0.7644 | Val Accuracy: 0.8063 | Val Loss: 0.4628\n","Epoch 53/200\n","188/188 [==============================] - 177s 943ms/step - loss: 0.7306 - accuracy: 0.7289 - val_loss: 0.4702 - val_accuracy: 0.8230 - lr: 0.0010\n","Accuracy: 0.7289 | Loss: 0.7306 | Val Accuracy: 0.8230 | Val Loss: 0.4702\n","Epoch 54/200\n","188/188 [==============================] - 170s 903ms/step - loss: 0.7432 - accuracy: 0.7281 - val_loss: 0.4867 - val_accuracy: 0.8079 - lr: 0.0010\n","Accuracy: 0.7281 | Loss: 0.7432 | Val Accuracy: 0.8079 | Val Loss: 0.4867\n","Epoch 55/200\n","188/188 [==============================] - 181s 963ms/step - loss: 0.7418 - accuracy: 0.7216 - val_loss: 0.4508 - val_accuracy: 0.8127 - lr: 0.0010\n","Accuracy: 0.7216 | Loss: 0.7418 | Val Accuracy: 0.8127 | Val Loss: 0.4508\n","Epoch 56/200\n","188/188 [==============================] - 182s 966ms/step - loss: 0.7035 - accuracy: 0.7352 - val_loss: 0.5368 - val_accuracy: 0.7889 - lr: 0.0010\n","Accuracy: 0.7352 | Loss: 0.7035 | Val Accuracy: 0.7889 | Val Loss: 0.5368\n","Epoch 57/200\n","188/188 [==============================] - 177s 940ms/step - loss: 0.6929 - accuracy: 0.7416 - val_loss: 0.4888 - val_accuracy: 0.8071 - lr: 0.0010\n","Accuracy: 0.7416 | Loss: 0.6929 | Val Accuracy: 0.8071 | Val Loss: 0.4888\n","Epoch 58/200\n","188/188 [==============================] - 187s 995ms/step - loss: 0.7228 - accuracy: 0.7312 - val_loss: 0.4339 - val_accuracy: 0.8302 - lr: 0.0010\n","Accuracy: 0.7312 | Loss: 0.7228 | Val Accuracy: 0.8302 | Val Loss: 0.4339\n","Epoch 59/200\n","188/188 [==============================] - 191s 1s/step - loss: 0.6874 - accuracy: 0.7466 - val_loss: 0.5454 - val_accuracy: 0.7881 - lr: 0.0010\n","Accuracy: 0.7466 | Loss: 0.6874 | Val Accuracy: 0.7881 | Val Loss: 0.5454\n","Epoch 60/200\n","188/188 [==============================] - 177s 943ms/step - loss: 0.7018 - accuracy: 0.7329 - val_loss: 0.4324 - val_accuracy: 0.8214 - lr: 0.0010\n","Accuracy: 0.7329 | Loss: 0.7018 | Val Accuracy: 0.8214 | Val Loss: 0.4324\n","Epoch 61/200\n","188/188 [==============================] - 174s 927ms/step - loss: 0.7255 - accuracy: 0.7392 - val_loss: 0.5106 - val_accuracy: 0.7905 - lr: 0.0010\n","Accuracy: 0.7392 | Loss: 0.7255 | Val Accuracy: 0.7905 | Val Loss: 0.5106\n","Epoch 62/200\n","188/188 [==============================] - 185s 983ms/step - loss: 0.6828 - accuracy: 0.7436 - val_loss: 0.4284 - val_accuracy: 0.8365 - lr: 0.0010\n","Accuracy: 0.7436 | Loss: 0.6828 | Val Accuracy: 0.8365 | Val Loss: 0.4284\n","Epoch 63/200\n","188/188 [==============================] - 173s 918ms/step - loss: 0.6768 - accuracy: 0.7487 - val_loss: 0.4376 - val_accuracy: 0.8397 - lr: 0.0010\n","Accuracy: 0.7487 | Loss: 0.6768 | Val Accuracy: 0.8397 | Val Loss: 0.4376\n","Epoch 64/200\n","188/188 [==============================] - 168s 894ms/step - loss: 0.6694 - accuracy: 0.7509 - val_loss: 0.4140 - val_accuracy: 0.8389 - lr: 0.0010\n","Accuracy: 0.7509 | Loss: 0.6694 | Val Accuracy: 0.8389 | Val Loss: 0.4140\n","Epoch 65/200\n","188/188 [==============================] - 170s 906ms/step - loss: 0.6713 - accuracy: 0.7593 - val_loss: 0.4178 - val_accuracy: 0.8429 - lr: 0.0010\n","Accuracy: 0.7593 | Loss: 0.6713 | Val Accuracy: 0.8429 | Val Loss: 0.4178\n","Epoch 66/200\n","188/188 [==============================] - 170s 902ms/step - loss: 0.6857 - accuracy: 0.7539 - val_loss: 0.4079 - val_accuracy: 0.8341 - lr: 0.0010\n","Accuracy: 0.7539 | Loss: 0.6857 | Val Accuracy: 0.8341 | Val Loss: 0.4079\n","Epoch 67/200\n","188/188 [==============================] - 167s 887ms/step - loss: 0.6459 - accuracy: 0.7621 - val_loss: 0.4149 - val_accuracy: 0.8421 - lr: 0.0010\n","Accuracy: 0.7621 | Loss: 0.6459 | Val Accuracy: 0.8421 | Val Loss: 0.4149\n","Epoch 68/200\n","188/188 [==============================] - 166s 884ms/step - loss: 0.6392 - accuracy: 0.7614 - val_loss: 0.4203 - val_accuracy: 0.8452 - lr: 0.0010\n","Accuracy: 0.7614 | Loss: 0.6392 | Val Accuracy: 0.8452 | Val Loss: 0.4203\n","Epoch 69/200\n","188/188 [==============================] - 166s 883ms/step - loss: 0.6306 - accuracy: 0.7703 - val_loss: 0.4802 - val_accuracy: 0.8071 - lr: 0.0010\n","Accuracy: 0.7703 | Loss: 0.6306 | Val Accuracy: 0.8071 | Val Loss: 0.4802\n","Epoch 70/200\n","188/188 [==============================] - 165s 879ms/step - loss: 0.6264 - accuracy: 0.7728 - val_loss: 0.4802 - val_accuracy: 0.8135 - lr: 0.0010\n","Accuracy: 0.7728 | Loss: 0.6264 | Val Accuracy: 0.8135 | Val Loss: 0.4802\n","Epoch 71/200\n"]},{"name":"stdout","output_type":"stream","text":["188/188 [==============================] - 166s 884ms/step - loss: 0.6387 - accuracy: 0.7709 - val_loss: 0.5182 - val_accuracy: 0.8103 - lr: 0.0010\n","Accuracy: 0.7709 | Loss: 0.6387 | Val Accuracy: 0.8103 | Val Loss: 0.5182\n","Epoch 72/200\n","188/188 [==============================] - 166s 884ms/step - loss: 0.6369 - accuracy: 0.7631 - val_loss: 0.4320 - val_accuracy: 0.8119 - lr: 0.0010\n","Accuracy: 0.7631 | Loss: 0.6369 | Val Accuracy: 0.8119 | Val Loss: 0.4320\n","Epoch 73/200\n","188/188 [==============================] - 166s 884ms/step - loss: 0.6521 - accuracy: 0.7583 - val_loss: 0.3892 - val_accuracy: 0.8651 - lr: 0.0010\n","Accuracy: 0.7583 | Loss: 0.6521 | Val Accuracy: 0.8651 | Val Loss: 0.3892\n","Epoch 74/200\n","188/188 [==============================] - 168s 891ms/step - loss: 0.6169 - accuracy: 0.7818 - val_loss: 0.3836 - val_accuracy: 0.8595 - lr: 0.0010\n","Accuracy: 0.7818 | Loss: 0.6169 | Val Accuracy: 0.8595 | Val Loss: 0.3836\n","Epoch 75/200\n","188/188 [==============================] - 165s 879ms/step - loss: 0.6069 - accuracy: 0.7878 - val_loss: 0.4406 - val_accuracy: 0.8405 - lr: 0.0010\n","Accuracy: 0.7878 | Loss: 0.6069 | Val Accuracy: 0.8405 | Val Loss: 0.4406\n","Epoch 76/200\n","188/188 [==============================] - 172s 913ms/step - loss: 0.6247 - accuracy: 0.7786 - val_loss: 0.4086 - val_accuracy: 0.8310 - lr: 0.0010\n","Accuracy: 0.7786 | Loss: 0.6247 | Val Accuracy: 0.8310 | Val Loss: 0.4086\n","Epoch 77/200\n","188/188 [==============================] - 194s 1s/step - loss: 0.6258 - accuracy: 0.7803 - val_loss: 0.3725 - val_accuracy: 0.8619 - lr: 0.0010\n","Accuracy: 0.7803 | Loss: 0.6258 | Val Accuracy: 0.8619 | Val Loss: 0.3725\n","Epoch 78/200\n","188/188 [==============================] - 184s 976ms/step - loss: 0.6109 - accuracy: 0.7781 - val_loss: 0.3732 - val_accuracy: 0.8659 - lr: 0.0010\n","Accuracy: 0.7781 | Loss: 0.6109 | Val Accuracy: 0.8659 | Val Loss: 0.3732\n","Epoch 79/200\n","188/188 [==============================] - 197s 1s/step - loss: 0.5943 - accuracy: 0.7951 - val_loss: 0.3832 - val_accuracy: 0.8651 - lr: 0.0010\n","Accuracy: 0.7951 | Loss: 0.5943 | Val Accuracy: 0.8651 | Val Loss: 0.3832\n","Epoch 80/200\n","188/188 [==============================] - 194s 1s/step - loss: 0.6178 - accuracy: 0.7843 - val_loss: 0.3927 - val_accuracy: 0.8492 - lr: 0.0010\n","Accuracy: 0.7843 | Loss: 0.6178 | Val Accuracy: 0.8492 | Val Loss: 0.3927\n","Epoch 81/200\n","188/188 [==============================] - 190s 1s/step - loss: 0.6306 - accuracy: 0.7779 - val_loss: 0.3743 - val_accuracy: 0.8714 - lr: 0.0010\n","Accuracy: 0.7779 | Loss: 0.6306 | Val Accuracy: 0.8714 | Val Loss: 0.3743\n","Epoch 82/200\n","188/188 [==============================] - 186s 992ms/step - loss: 0.6003 - accuracy: 0.7858 - val_loss: 0.3627 - val_accuracy: 0.8690 - lr: 0.0010\n","Accuracy: 0.7858 | Loss: 0.6003 | Val Accuracy: 0.8690 | Val Loss: 0.3627\n","Epoch 83/200\n","188/188 [==============================] - 193s 1s/step - loss: 0.5900 - accuracy: 0.7964 - val_loss: 0.3901 - val_accuracy: 0.8587 - lr: 0.0010\n","Accuracy: 0.7964 | Loss: 0.5900 | Val Accuracy: 0.8587 | Val Loss: 0.3901\n","Epoch 84/200\n","188/188 [==============================] - 204s 1s/step - loss: 0.6240 - accuracy: 0.7794 - val_loss: 0.3623 - val_accuracy: 0.8770 - lr: 0.0010\n","Accuracy: 0.7794 | Loss: 0.6240 | Val Accuracy: 0.8770 | Val Loss: 0.3623\n","Epoch 85/200\n","188/188 [==============================] - 200s 1s/step - loss: 0.5876 - accuracy: 0.7953 - val_loss: 0.3914 - val_accuracy: 0.8492 - lr: 0.0010\n","Accuracy: 0.7953 | Loss: 0.5876 | Val Accuracy: 0.8492 | Val Loss: 0.3914\n","Epoch 86/200\n","188/188 [==============================] - 197s 1s/step - loss: 0.6208 - accuracy: 0.7821 - val_loss: 0.4117 - val_accuracy: 0.8500 - lr: 0.0010\n","Accuracy: 0.7821 | Loss: 0.6208 | Val Accuracy: 0.8500 | Val Loss: 0.4117\n","Epoch 87/200\n","188/188 [==============================] - 194s 1s/step - loss: 0.5779 - accuracy: 0.7938 - val_loss: 0.4062 - val_accuracy: 0.8675 - lr: 0.0010\n","Accuracy: 0.7938 | Loss: 0.5779 | Val Accuracy: 0.8675 | Val Loss: 0.4062\n","Epoch 88/200\n","188/188 [==============================] - 197s 1s/step - loss: 0.6096 - accuracy: 0.7876 - val_loss: 0.3803 - val_accuracy: 0.8706 - lr: 0.0010\n","Accuracy: 0.7876 | Loss: 0.6096 | Val Accuracy: 0.8706 | Val Loss: 0.3803\n","Epoch 89/200\n","188/188 [==============================] - 203s 1s/step - loss: 0.5927 - accuracy: 0.7949 - val_loss: 0.4148 - val_accuracy: 0.8611 - lr: 0.0010\n","Accuracy: 0.7949 | Loss: 0.5927 | Val Accuracy: 0.8611 | Val Loss: 0.4148\n","Epoch 90/200\n","188/188 [==============================] - 194s 1s/step - loss: 0.6216 - accuracy: 0.7949 - val_loss: 0.3930 - val_accuracy: 0.8595 - lr: 0.0010\n","Accuracy: 0.7949 | Loss: 0.6216 | Val Accuracy: 0.8595 | Val Loss: 0.3930\n","Epoch 91/200\n","188/188 [==============================] - 189s 1s/step - loss: 0.5787 - accuracy: 0.8094 - val_loss: 0.3512 - val_accuracy: 0.8849 - lr: 0.0010\n","Accuracy: 0.8094 | Loss: 0.5787 | Val Accuracy: 0.8849 | Val Loss: 0.3512\n","Epoch 92/200\n","188/188 [==============================] - 187s 997ms/step - loss: 0.5608 - accuracy: 0.8063 - val_loss: 0.3439 - val_accuracy: 0.8849 - lr: 0.0010\n","Accuracy: 0.8063 | Loss: 0.5608 | Val Accuracy: 0.8849 | Val Loss: 0.3439\n","Epoch 93/200\n","188/188 [==============================] - 206s 1s/step - loss: 0.5775 - accuracy: 0.8026 - val_loss: 0.3708 - val_accuracy: 0.8762 - lr: 0.0010\n","Accuracy: 0.8026 | Loss: 0.5775 | Val Accuracy: 0.8762 | Val Loss: 0.3708\n","Epoch 94/200\n","188/188 [==============================] - 207s 1s/step - loss: 0.5867 - accuracy: 0.8046 - val_loss: 0.3810 - val_accuracy: 0.8706 - lr: 0.0010\n","Accuracy: 0.8046 | Loss: 0.5867 | Val Accuracy: 0.8706 | Val Loss: 0.3810\n","Epoch 95/200\n","188/188 [==============================] - 189s 1s/step - loss: 0.5791 - accuracy: 0.8119 - val_loss: 0.3815 - val_accuracy: 0.8651 - lr: 0.0010\n","Accuracy: 0.8119 | Loss: 0.5791 | Val Accuracy: 0.8651 | Val Loss: 0.3815\n","Epoch 96/200\n","188/188 [==============================] - 197s 1s/step - loss: 0.5696 - accuracy: 0.8091 - val_loss: 0.3958 - val_accuracy: 0.8619 - lr: 0.0010\n","Accuracy: 0.8091 | Loss: 0.5696 | Val Accuracy: 0.8619 | Val Loss: 0.3958\n","Epoch 97/200\n","188/188 [==============================] - 198s 1s/step - loss: 0.5905 - accuracy: 0.8046 - val_loss: 0.4198 - val_accuracy: 0.8571 - lr: 0.0010\n","Accuracy: 0.8046 | Loss: 0.5905 | Val Accuracy: 0.8571 | Val Loss: 0.4198\n","Epoch 98/200\n","188/188 [==============================] - 196s 1s/step - loss: 0.5709 - accuracy: 0.8153 - val_loss: 0.3602 - val_accuracy: 0.8849 - lr: 0.0010\n","Accuracy: 0.8153 | Loss: 0.5709 | Val Accuracy: 0.8849 | Val Loss: 0.3602\n","Epoch 99/200\n","188/188 [==============================] - 196s 1s/step - loss: 0.5369 - accuracy: 0.8231 - val_loss: 0.3760 - val_accuracy: 0.8810 - lr: 0.0010\n","Accuracy: 0.8231 | Loss: 0.5369 | Val Accuracy: 0.8810 | Val Loss: 0.3760\n","Epoch 100/200\n","188/188 [==============================] - 200s 1s/step - loss: 0.5663 - accuracy: 0.8118 - val_loss: 0.3964 - val_accuracy: 0.8770 - lr: 0.0010\n","Accuracy: 0.8118 | Loss: 0.5663 | Val Accuracy: 0.8770 | Val Loss: 0.3964\n","Epoch 101/200\n","188/188 [==============================] - 190s 1s/step - loss: 0.5598 - accuracy: 0.8073 - val_loss: 0.3438 - val_accuracy: 0.8889 - lr: 0.0010\n","Accuracy: 0.8073 | Loss: 0.5598 | Val Accuracy: 0.8889 | Val Loss: 0.3438\n","Epoch 102/200\n","188/188 [==============================] - 194s 1s/step - loss: 0.5494 - accuracy: 0.8231 - val_loss: 0.3506 - val_accuracy: 0.8810 - lr: 0.0010\n","Accuracy: 0.8231 | Loss: 0.5494 | Val Accuracy: 0.8810 | Val Loss: 0.3506\n","Epoch 103/200\n","188/188 [==============================] - 197s 1s/step - loss: 0.5455 - accuracy: 0.8326 - val_loss: 0.3482 - val_accuracy: 0.8857 - lr: 0.0010\n","Accuracy: 0.8326 | Loss: 0.5455 | Val Accuracy: 0.8857 | Val Loss: 0.3482\n","Epoch 104/200\n","188/188 [==============================] - 190s 1s/step - loss: 0.5605 - accuracy: 0.8198 - val_loss: 0.3460 - val_accuracy: 0.8944 - lr: 0.0010\n","Accuracy: 0.8198 | Loss: 0.5605 | Val Accuracy: 0.8944 | Val Loss: 0.3460\n","Epoch 105/200\n","188/188 [==============================] - 183s 972ms/step - loss: 0.5524 - accuracy: 0.8169 - val_loss: 0.3489 - val_accuracy: 0.8841 - lr: 0.0010\n","Accuracy: 0.8169 | Loss: 0.5524 | Val Accuracy: 0.8841 | Val Loss: 0.3489\n","Epoch 106/200\n","188/188 [==============================] - 198s 1s/step - loss: 0.5781 - accuracy: 0.8126 - val_loss: 0.3450 - val_accuracy: 0.8849 - lr: 0.0010\n","Accuracy: 0.8126 | Loss: 0.5781 | Val Accuracy: 0.8849 | Val Loss: 0.3450\n","Epoch 107/200\n","188/188 [==============================] - 214s 1s/step - loss: 0.5512 - accuracy: 0.8274 - val_loss: 0.3631 - val_accuracy: 0.8817 - lr: 0.0010\n","Accuracy: 0.8274 | Loss: 0.5512 | Val Accuracy: 0.8817 | Val Loss: 0.3631\n","Epoch 108/200\n","188/188 [==============================] - 191s 1s/step - loss: 0.5526 - accuracy: 0.8311 - val_loss: 0.3625 - val_accuracy: 0.8825 - lr: 0.0010\n","Accuracy: 0.8311 | Loss: 0.5526 | Val Accuracy: 0.8825 | Val Loss: 0.3625\n","Epoch 109/200\n","188/188 [==============================] - 200s 1s/step - loss: 0.5546 - accuracy: 0.8231 - val_loss: 0.3687 - val_accuracy: 0.8921 - lr: 0.0010\n","Accuracy: 0.8231 | Loss: 0.5546 | Val Accuracy: 0.8921 | Val Loss: 0.3687\n","Epoch 110/200\n","188/188 [==============================] - 222s 1s/step - loss: 0.5328 - accuracy: 0.8334 - val_loss: 0.3439 - val_accuracy: 0.8905 - lr: 0.0010\n","Accuracy: 0.8334 | Loss: 0.5328 | Val Accuracy: 0.8905 | Val Loss: 0.3439\n","Epoch 111/200\n","188/188 [==============================] - 200s 1s/step - loss: 0.5342 - accuracy: 0.8268 - val_loss: 0.3487 - val_accuracy: 0.8984 - lr: 0.0010\n","Accuracy: 0.8268 | Loss: 0.5342 | Val Accuracy: 0.8984 | Val Loss: 0.3487\n","Epoch 112/200\n","188/188 [==============================] - 192s 1s/step - loss: 0.5549 - accuracy: 0.8208 - val_loss: 0.4188 - val_accuracy: 0.8738 - lr: 0.0010\n","Accuracy: 0.8208 | Loss: 0.5549 | Val Accuracy: 0.8738 | Val Loss: 0.4188\n","Epoch 113/200\n","188/188 [==============================] - 194s 1s/step - loss: 0.5644 - accuracy: 0.8196 - val_loss: 0.3795 - val_accuracy: 0.8841 - lr: 0.0010\n","Accuracy: 0.8196 | Loss: 0.5644 | Val Accuracy: 0.8841 | Val Loss: 0.3795\n","Epoch 114/200\n","188/188 [==============================] - 189s 1s/step - loss: 0.5649 - accuracy: 0.8196 - val_loss: 0.3913 - val_accuracy: 0.8611 - lr: 0.0010\n","Accuracy: 0.8196 | Loss: 0.5649 | Val Accuracy: 0.8611 | Val Loss: 0.3913\n","Epoch 115/200\n","188/188 [==============================] - 198s 1s/step - loss: 0.5484 - accuracy: 0.8264 - val_loss: 0.5074 - val_accuracy: 0.8429 - lr: 0.0010\n","Accuracy: 0.8264 | Loss: 0.5484 | Val Accuracy: 0.8429 | Val Loss: 0.5074\n","Epoch 116/200\n","188/188 [==============================] - 195s 1s/step - loss: 0.5362 - accuracy: 0.8346 - val_loss: 0.3613 - val_accuracy: 0.8857 - lr: 0.0010\n","Accuracy: 0.8346 | Loss: 0.5362 | Val Accuracy: 0.8857 | Val Loss: 0.3613\n","Epoch 117/200\n","188/188 [==============================] - 188s 1000ms/step - loss: 0.5274 - accuracy: 0.8401 - val_loss: 0.3519 - val_accuracy: 0.9016 - lr: 0.0010\n","Accuracy: 0.8401 | Loss: 0.5274 | Val Accuracy: 0.9016 | Val Loss: 0.3519\n","Epoch 118/200\n","188/188 [==============================] - 179s 953ms/step - loss: 0.5298 - accuracy: 0.8339 - val_loss: 0.3720 - val_accuracy: 0.8921 - lr: 0.0010\n","Accuracy: 0.8339 | Loss: 0.5298 | Val Accuracy: 0.8921 | Val Loss: 0.3720\n","Epoch 119/200\n","188/188 [==============================] - 191s 1s/step - loss: 0.5455 - accuracy: 0.8366 - val_loss: 0.3618 - val_accuracy: 0.9008 - lr: 0.0010\n","Accuracy: 0.8366 | Loss: 0.5455 | Val Accuracy: 0.9008 | Val Loss: 0.3618\n","Epoch 120/200\n","188/188 [==============================] - 195s 1s/step - loss: 0.5411 - accuracy: 0.8388 - val_loss: 0.3637 - val_accuracy: 0.8802 - lr: 0.0010\n","Accuracy: 0.8388 | Loss: 0.5411 | Val Accuracy: 0.8802 | Val Loss: 0.3637\n","Epoch 121/200\n","188/188 [==============================] - 193s 1s/step - loss: 0.5433 - accuracy: 0.8368 - val_loss: 0.3368 - val_accuracy: 0.8968 - lr: 0.0010\n","Accuracy: 0.8368 | Loss: 0.5433 | Val Accuracy: 0.8968 | Val Loss: 0.3368\n","Epoch 122/200\n","188/188 [==============================] - 186s 990ms/step - loss: 0.5524 - accuracy: 0.8331 - val_loss: 0.3502 - val_accuracy: 0.8937 - lr: 0.0010\n","Accuracy: 0.8331 | Loss: 0.5524 | Val Accuracy: 0.8937 | Val Loss: 0.3502\n","Epoch 123/200\n","188/188 [==============================] - 183s 970ms/step - loss: 0.5295 - accuracy: 0.8379 - val_loss: 0.3901 - val_accuracy: 0.8913 - lr: 0.0010\n","Accuracy: 0.8379 | Loss: 0.5295 | Val Accuracy: 0.8913 | Val Loss: 0.3901\n","Epoch 124/200\n","188/188 [==============================] - 188s 999ms/step - loss: 0.5587 - accuracy: 0.8288 - val_loss: 0.5347 - val_accuracy: 0.8389 - lr: 0.0010\n","Accuracy: 0.8288 | Loss: 0.5587 | Val Accuracy: 0.8389 | Val Loss: 0.5347\n","Epoch 125/200\n","188/188 [==============================] - 219s 1s/step - loss: 0.5282 - accuracy: 0.8424 - val_loss: 0.3742 - val_accuracy: 0.8825 - lr: 0.0010\n","Accuracy: 0.8424 | Loss: 0.5282 | Val Accuracy: 0.8825 | Val Loss: 0.3742\n","Epoch 126/200\n","188/188 [==============================] - 203s 1s/step - loss: 0.5486 - accuracy: 0.8361 - val_loss: 0.3613 - val_accuracy: 0.9079 - lr: 0.0010\n","Accuracy: 0.8361 | Loss: 0.5486 | Val Accuracy: 0.9079 | Val Loss: 0.3613\n","Epoch 127/200\n","188/188 [==============================] - 196s 1s/step - loss: 0.5081 - accuracy: 0.8526 - val_loss: 0.6736 - val_accuracy: 0.8048 - lr: 0.0010\n","Accuracy: 0.8526 | Loss: 0.5081 | Val Accuracy: 0.8048 | Val Loss: 0.6736\n","Epoch 128/200\n","188/188 [==============================] - 250s 1s/step - loss: 0.5056 - accuracy: 0.8505 - val_loss: 0.3455 - val_accuracy: 0.9016 - lr: 0.0010\n","Accuracy: 0.8505 | Loss: 0.5056 | Val Accuracy: 0.9016 | Val Loss: 0.3455\n","Epoch 129/200\n","188/188 [==============================] - 198s 1s/step - loss: 0.5196 - accuracy: 0.8436 - val_loss: 0.3385 - val_accuracy: 0.9143 - lr: 0.0010\n","Accuracy: 0.8436 | Loss: 0.5196 | Val Accuracy: 0.9143 | Val Loss: 0.3385\n","Epoch 130/200\n","188/188 [==============================] - 225s 1s/step - loss: 0.5185 - accuracy: 0.8496 - val_loss: 0.3285 - val_accuracy: 0.9167 - lr: 0.0010\n","Accuracy: 0.8496 | Loss: 0.5185 | Val Accuracy: 0.9167 | Val Loss: 0.3285\n","Epoch 131/200\n","188/188 [==============================] - 195s 1s/step - loss: 0.5095 - accuracy: 0.8525 - val_loss: 0.3373 - val_accuracy: 0.8889 - lr: 0.0010\n","Accuracy: 0.8525 | Loss: 0.5095 | Val Accuracy: 0.8889 | Val Loss: 0.3373\n","Epoch 132/200\n","188/188 [==============================] - 185s 983ms/step - loss: 0.5262 - accuracy: 0.8421 - val_loss: 0.3365 - val_accuracy: 0.9190 - lr: 0.0010\n","Accuracy: 0.8421 | Loss: 0.5262 | Val Accuracy: 0.9190 | Val Loss: 0.3365\n","Epoch 133/200\n","188/188 [==============================] - 186s 989ms/step - loss: 0.5042 - accuracy: 0.8553 - val_loss: 0.3367 - val_accuracy: 0.9159 - lr: 0.0010\n","Accuracy: 0.8553 | Loss: 0.5042 | Val Accuracy: 0.9159 | Val Loss: 0.3367\n","Epoch 134/200\n","188/188 [==============================] - 209s 1s/step - loss: 0.5239 - accuracy: 0.8454 - val_loss: 0.3468 - val_accuracy: 0.9016 - lr: 0.0010\n","Accuracy: 0.8454 | Loss: 0.5239 | Val Accuracy: 0.9016 | Val Loss: 0.3468\n","Epoch 135/200\n","188/188 [==============================] - 189s 1s/step - loss: 0.5130 - accuracy: 0.8466 - val_loss: 0.3606 - val_accuracy: 0.8873 - lr: 0.0010\n","Accuracy: 0.8466 | Loss: 0.5130 | Val Accuracy: 0.8873 | Val Loss: 0.3606\n","Epoch 136/200\n","188/188 [==============================] - 198s 1s/step - loss: 0.5270 - accuracy: 0.8479 - val_loss: 0.3479 - val_accuracy: 0.9198 - lr: 0.0010\n","Accuracy: 0.8479 | Loss: 0.5270 | Val Accuracy: 0.9198 | Val Loss: 0.3479\n","Epoch 137/200\n","188/188 [==============================] - 202s 1s/step - loss: 0.5407 - accuracy: 0.8498 - val_loss: 0.3313 - val_accuracy: 0.9159 - lr: 0.0010\n","Accuracy: 0.8498 | Loss: 0.5407 | Val Accuracy: 0.9159 | Val Loss: 0.3313\n","Epoch 138/200\n","188/188 [==============================] - 193s 1s/step - loss: 0.4995 - accuracy: 0.8635 - val_loss: 0.3490 - val_accuracy: 0.9198 - lr: 0.0010\n","Accuracy: 0.8635 | Loss: 0.4995 | Val Accuracy: 0.9198 | Val Loss: 0.3490\n","Epoch 139/200\n","188/188 [==============================] - 199s 1s/step - loss: 0.5087 - accuracy: 0.8576 - val_loss: 0.3376 - val_accuracy: 0.9095 - lr: 0.0010\n","Accuracy: 0.8576 | Loss: 0.5087 | Val Accuracy: 0.9095 | Val Loss: 0.3376\n","Epoch 140/200\n","188/188 [==============================] - 196s 1s/step - loss: 0.4990 - accuracy: 0.8635 - val_loss: 0.3881 - val_accuracy: 0.9008 - lr: 0.0010\n","Accuracy: 0.8635 | Loss: 0.4990 | Val Accuracy: 0.9008 | Val Loss: 0.3881\n","Epoch 141/200\n"]},{"name":"stdout","output_type":"stream","text":["188/188 [==============================] - 197s 1s/step - loss: 0.5297 - accuracy: 0.8540 - val_loss: 0.3387 - val_accuracy: 0.9262 - lr: 0.0010\n","Accuracy: 0.8540 | Loss: 0.5297 | Val Accuracy: 0.9262 | Val Loss: 0.3387\n","Epoch 142/200\n","188/188 [==============================] - 190s 1s/step - loss: 0.5119 - accuracy: 0.8633 - val_loss: 0.3318 - val_accuracy: 0.9302 - lr: 0.0010\n","Accuracy: 0.8633 | Loss: 0.5119 | Val Accuracy: 0.9302 | Val Loss: 0.3318\n","Epoch 143/200\n","188/188 [==============================] - 187s 997ms/step - loss: 0.5005 - accuracy: 0.8666 - val_loss: 0.3217 - val_accuracy: 0.9222 - lr: 0.0010\n","Accuracy: 0.8666 | Loss: 0.5005 | Val Accuracy: 0.9222 | Val Loss: 0.3217\n","Epoch 144/200\n","188/188 [==============================] - 200s 1s/step - loss: 0.4925 - accuracy: 0.8661 - val_loss: 0.3653 - val_accuracy: 0.9056 - lr: 0.0010\n","Accuracy: 0.8661 | Loss: 0.4925 | Val Accuracy: 0.9056 | Val Loss: 0.3653\n","Epoch 145/200\n","188/188 [==============================] - 207s 1s/step - loss: 0.5180 - accuracy: 0.8505 - val_loss: 0.3766 - val_accuracy: 0.8873 - lr: 0.0010\n","Accuracy: 0.8505 | Loss: 0.5180 | Val Accuracy: 0.8873 | Val Loss: 0.3766\n","Epoch 146/200\n","188/188 [==============================] - 194s 1s/step - loss: 0.4912 - accuracy: 0.8626 - val_loss: 0.3336 - val_accuracy: 0.9198 - lr: 0.0010\n","Accuracy: 0.8626 | Loss: 0.4912 | Val Accuracy: 0.9198 | Val Loss: 0.3336\n","Epoch 147/200\n","188/188 [==============================] - 198s 1s/step - loss: 0.4860 - accuracy: 0.8703 - val_loss: 0.3353 - val_accuracy: 0.9167 - lr: 0.0010\n","Accuracy: 0.8703 | Loss: 0.4860 | Val Accuracy: 0.9167 | Val Loss: 0.3353\n","Epoch 148/200\n","188/188 [==============================] - 197s 1s/step - loss: 0.5108 - accuracy: 0.8658 - val_loss: 0.3331 - val_accuracy: 0.9325 - lr: 0.0010\n","Accuracy: 0.8658 | Loss: 0.5108 | Val Accuracy: 0.9325 | Val Loss: 0.3331\n","Epoch 149/200\n","188/188 [==============================] - 192s 1s/step - loss: 0.5134 - accuracy: 0.8658 - val_loss: 0.3273 - val_accuracy: 0.9341 - lr: 0.0010\n","Accuracy: 0.8658 | Loss: 0.5134 | Val Accuracy: 0.9341 | Val Loss: 0.3273\n","Epoch 150/200\n","188/188 [==============================] - 205s 1s/step - loss: 0.4971 - accuracy: 0.8701 - val_loss: 0.3236 - val_accuracy: 0.9317 - lr: 0.0010\n","Accuracy: 0.8701 | Loss: 0.4971 | Val Accuracy: 0.9317 | Val Loss: 0.3236\n","Epoch 151/200\n","188/188 [==============================] - 195s 1s/step - loss: 0.5076 - accuracy: 0.8658 - val_loss: 0.3195 - val_accuracy: 0.9325 - lr: 0.0010\n","Accuracy: 0.8658 | Loss: 0.5076 | Val Accuracy: 0.9325 | Val Loss: 0.3195\n","Epoch 152/200\n","188/188 [==============================] - 197s 1s/step - loss: 0.5026 - accuracy: 0.8745 - val_loss: 0.3396 - val_accuracy: 0.9238 - lr: 0.0010\n","Accuracy: 0.8745 | Loss: 0.5026 | Val Accuracy: 0.9238 | Val Loss: 0.3396\n","Epoch 153/200\n","188/188 [==============================] - 203s 1s/step - loss: 0.4802 - accuracy: 0.8721 - val_loss: 0.3383 - val_accuracy: 0.9183 - lr: 0.0010\n","Accuracy: 0.8721 | Loss: 0.4802 | Val Accuracy: 0.9183 | Val Loss: 0.3383\n","Epoch 154/200\n","188/188 [==============================] - 199s 1s/step - loss: 0.4670 - accuracy: 0.8816 - val_loss: 0.3266 - val_accuracy: 0.9238 - lr: 0.0010\n","Accuracy: 0.8816 | Loss: 0.4670 | Val Accuracy: 0.9238 | Val Loss: 0.3266\n","Epoch 155/200\n","188/188 [==============================] - 202s 1s/step - loss: 0.5018 - accuracy: 0.8743 - val_loss: 0.3310 - val_accuracy: 0.9437 - lr: 0.0010\n","Accuracy: 0.8743 | Loss: 0.5018 | Val Accuracy: 0.9437 | Val Loss: 0.3310\n","Epoch 156/200\n","188/188 [==============================] - 204s 1s/step - loss: 0.4856 - accuracy: 0.8751 - val_loss: 0.3085 - val_accuracy: 0.9397 - lr: 0.0010\n","Accuracy: 0.8751 | Loss: 0.4856 | Val Accuracy: 0.9397 | Val Loss: 0.3085\n","Epoch 157/200\n","188/188 [==============================] - 202s 1s/step - loss: 0.5025 - accuracy: 0.8716 - val_loss: 0.3309 - val_accuracy: 0.9373 - lr: 0.0010\n","Accuracy: 0.8716 | Loss: 0.5025 | Val Accuracy: 0.9373 | Val Loss: 0.3309\n","Epoch 158/200\n","188/188 [==============================] - 208s 1s/step - loss: 0.4946 - accuracy: 0.8808 - val_loss: 0.3146 - val_accuracy: 0.9381 - lr: 0.0010\n","Accuracy: 0.8808 | Loss: 0.4946 | Val Accuracy: 0.9381 | Val Loss: 0.3146\n","Epoch 159/200\n","188/188 [==============================] - 258s 1s/step - loss: 0.5154 - accuracy: 0.8723 - val_loss: 0.3167 - val_accuracy: 0.9500 - lr: 0.0010\n","Accuracy: 0.8723 | Loss: 0.5154 | Val Accuracy: 0.9500 | Val Loss: 0.3167\n","Epoch 160/200\n","188/188 [==============================] - 292s 2s/step - loss: 0.5021 - accuracy: 0.8783 - val_loss: 0.3432 - val_accuracy: 0.9175 - lr: 0.0010\n","Accuracy: 0.8783 | Loss: 0.5021 | Val Accuracy: 0.9175 | Val Loss: 0.3432\n","Epoch 161/200\n","188/188 [==============================] - 284s 2s/step - loss: 0.4788 - accuracy: 0.8830 - val_loss: 0.3697 - val_accuracy: 0.9119 - lr: 0.0010\n","Accuracy: 0.8830 | Loss: 0.4788 | Val Accuracy: 0.9119 | Val Loss: 0.3697\n","Epoch 162/200\n","188/188 [==============================] - 267s 1s/step - loss: 0.4816 - accuracy: 0.8820 - val_loss: 0.3346 - val_accuracy: 0.9468 - lr: 0.0010\n","Accuracy: 0.8820 | Loss: 0.4816 | Val Accuracy: 0.9468 | Val Loss: 0.3346\n","Epoch 163/200\n","188/188 [==============================] - 190s 1s/step - loss: 0.4811 - accuracy: 0.8826 - val_loss: 0.3497 - val_accuracy: 0.9333 - lr: 0.0010\n","Accuracy: 0.8826 | Loss: 0.4811 | Val Accuracy: 0.9333 | Val Loss: 0.3497\n","Epoch 164/200\n","188/188 [==============================] - 230s 1s/step - loss: 0.4788 - accuracy: 0.8831 - val_loss: 0.3262 - val_accuracy: 0.9294 - lr: 0.0010\n","Accuracy: 0.8831 | Loss: 0.4788 | Val Accuracy: 0.9294 | Val Loss: 0.3262\n","Epoch 165/200\n","188/188 [==============================] - 191s 1s/step - loss: 0.5970 - accuracy: 0.8561 - val_loss: 0.3429 - val_accuracy: 0.9413 - lr: 0.0010\n","Accuracy: 0.8561 | Loss: 0.5970 | Val Accuracy: 0.9413 | Val Loss: 0.3429\n","Epoch 166/200\n","188/188 [==============================] - 193s 1s/step - loss: 0.5240 - accuracy: 0.8748 - val_loss: 0.3113 - val_accuracy: 0.9540 - lr: 0.0010\n","Accuracy: 0.8748 | Loss: 0.5240 | Val Accuracy: 0.9540 | Val Loss: 0.3113\n","Epoch 167/200\n","188/188 [==============================] - 203s 1s/step - loss: 0.4826 - accuracy: 0.8828 - val_loss: 0.3092 - val_accuracy: 0.9484 - lr: 0.0010\n","Accuracy: 0.8828 | Loss: 0.4826 | Val Accuracy: 0.9484 | Val Loss: 0.3092\n","Epoch 168/200\n","188/188 [==============================] - 198s 1s/step - loss: 0.4836 - accuracy: 0.8868 - val_loss: 0.3074 - val_accuracy: 0.9571 - lr: 0.0010\n","Accuracy: 0.8868 | Loss: 0.4836 | Val Accuracy: 0.9571 | Val Loss: 0.3074\n","Epoch 169/200\n","188/188 [==============================] - 211s 1s/step - loss: 0.4812 - accuracy: 0.8901 - val_loss: 0.3114 - val_accuracy: 0.9429 - lr: 0.0010\n","Accuracy: 0.8901 | Loss: 0.4812 | Val Accuracy: 0.9429 | Val Loss: 0.3114\n","Epoch 170/200\n","188/188 [==============================] - 205s 1s/step - loss: 0.4729 - accuracy: 0.8916 - val_loss: 0.4132 - val_accuracy: 0.9206 - lr: 0.0010\n","Accuracy: 0.8916 | Loss: 0.4729 | Val Accuracy: 0.9206 | Val Loss: 0.4132\n","Epoch 171/200\n","188/188 [==============================] - 197s 1s/step - loss: 0.4684 - accuracy: 0.8938 - val_loss: 0.3087 - val_accuracy: 0.9587 - lr: 0.0010\n","Accuracy: 0.8938 | Loss: 0.4684 | Val Accuracy: 0.9587 | Val Loss: 0.3087\n","Epoch 172/200\n","188/188 [==============================] - 195s 1s/step - loss: 0.4735 - accuracy: 0.8926 - val_loss: 0.3004 - val_accuracy: 0.9643 - lr: 0.0010\n","Accuracy: 0.8926 | Loss: 0.4735 | Val Accuracy: 0.9643 | Val Loss: 0.3004\n","Epoch 173/200\n","188/188 [==============================] - 195s 1s/step - loss: 0.4673 - accuracy: 0.8943 - val_loss: 0.3180 - val_accuracy: 0.9540 - lr: 0.0010\n","Accuracy: 0.8943 | Loss: 0.4673 | Val Accuracy: 0.9540 | Val Loss: 0.3180\n","Epoch 174/200\n","188/188 [==============================] - 198s 1s/step - loss: 0.4751 - accuracy: 0.8941 - val_loss: 0.3029 - val_accuracy: 0.9571 - lr: 0.0010\n","Accuracy: 0.8941 | Loss: 0.4751 | Val Accuracy: 0.9571 | Val Loss: 0.3029\n","Epoch 175/200\n","188/188 [==============================] - 198s 1s/step - loss: 0.4624 - accuracy: 0.8980 - val_loss: 0.2903 - val_accuracy: 0.9611 - lr: 0.0010\n","Accuracy: 0.8980 | Loss: 0.4624 | Val Accuracy: 0.9611 | Val Loss: 0.2903\n","Epoch 176/200\n","188/188 [==============================] - 211s 1s/step - loss: 0.4862 - accuracy: 0.8953 - val_loss: 0.3266 - val_accuracy: 0.9508 - lr: 0.0010\n","Accuracy: 0.8953 | Loss: 0.4862 | Val Accuracy: 0.9508 | Val Loss: 0.3266\n","Epoch 177/200\n","188/188 [==============================] - 193s 1s/step - loss: 0.4652 - accuracy: 0.8986 - val_loss: 0.2866 - val_accuracy: 0.9683 - lr: 0.0010\n","Accuracy: 0.8986 | Loss: 0.4652 | Val Accuracy: 0.9683 | Val Loss: 0.2866\n","Epoch 178/200\n","188/188 [==============================] - 194s 1s/step - loss: 0.4415 - accuracy: 0.9106 - val_loss: 0.2761 - val_accuracy: 0.9722 - lr: 0.0010\n","Accuracy: 0.9106 | Loss: 0.4415 | Val Accuracy: 0.9722 | Val Loss: 0.2761\n","Epoch 179/200\n","188/188 [==============================] - 196s 1s/step - loss: 0.4532 - accuracy: 0.9030 - val_loss: 0.2917 - val_accuracy: 0.9611 - lr: 0.0010\n","Accuracy: 0.9030 | Loss: 0.4532 | Val Accuracy: 0.9611 | Val Loss: 0.2917\n","Epoch 180/200\n","188/188 [==============================] - 199s 1s/step - loss: 0.4591 - accuracy: 0.9056 - val_loss: 0.3003 - val_accuracy: 0.9683 - lr: 0.0010\n","Accuracy: 0.9056 | Loss: 0.4591 | Val Accuracy: 0.9683 | Val Loss: 0.3003\n","Epoch 181/200\n","188/188 [==============================] - 203s 1s/step - loss: 0.4382 - accuracy: 0.9071 - val_loss: 0.3066 - val_accuracy: 0.9532 - lr: 0.0010\n","Accuracy: 0.9071 | Loss: 0.4382 | Val Accuracy: 0.9532 | Val Loss: 0.3066\n","Epoch 182/200\n","188/188 [==============================] - 193s 1s/step - loss: 0.4485 - accuracy: 0.9035 - val_loss: 0.2807 - val_accuracy: 0.9714 - lr: 0.0010\n","Accuracy: 0.9035 | Loss: 0.4485 | Val Accuracy: 0.9714 | Val Loss: 0.2807\n","Epoch 183/200\n","188/188 [==============================] - 216s 1s/step - loss: 0.4731 - accuracy: 0.9023 - val_loss: 0.2934 - val_accuracy: 0.9690 - lr: 0.0010\n","Accuracy: 0.9023 | Loss: 0.4731 | Val Accuracy: 0.9690 | Val Loss: 0.2934\n","Epoch 184/200\n","188/188 [==============================] - 222s 1s/step - loss: 0.4532 - accuracy: 0.9076 - val_loss: 0.2824 - val_accuracy: 0.9675 - lr: 0.0010\n","Accuracy: 0.9076 | Loss: 0.4532 | Val Accuracy: 0.9675 | Val Loss: 0.2824\n","Epoch 185/200\n","188/188 [==============================] - 202s 1s/step - loss: 0.4631 - accuracy: 0.9078 - val_loss: 0.2884 - val_accuracy: 0.9706 - lr: 0.0010\n","Accuracy: 0.9078 | Loss: 0.4631 | Val Accuracy: 0.9706 | Val Loss: 0.2884\n","Epoch 186/200\n","188/188 [==============================] - 204s 1s/step - loss: 0.4693 - accuracy: 0.9003 - val_loss: 0.3094 - val_accuracy: 0.9579 - lr: 0.0010\n","Accuracy: 0.9003 | Loss: 0.4693 | Val Accuracy: 0.9579 | Val Loss: 0.3094\n","Epoch 187/200\n","188/188 [==============================] - 205s 1s/step - loss: 0.4446 - accuracy: 0.9100 - val_loss: 0.2666 - val_accuracy: 0.9762 - lr: 0.0010\n","Accuracy: 0.9100 | Loss: 0.4446 | Val Accuracy: 0.9762 | Val Loss: 0.2666\n","Epoch 188/200\n","188/188 [==============================] - 198s 1s/step - loss: 0.4487 - accuracy: 0.9133 - val_loss: 0.2954 - val_accuracy: 0.9690 - lr: 0.0010\n","Accuracy: 0.9133 | Loss: 0.4487 | Val Accuracy: 0.9690 | Val Loss: 0.2954\n","Epoch 189/200\n","188/188 [==============================] - 208s 1s/step - loss: 0.4649 - accuracy: 0.9091 - val_loss: 0.2925 - val_accuracy: 0.9746 - lr: 0.0010\n","Accuracy: 0.9091 | Loss: 0.4649 | Val Accuracy: 0.9746 | Val Loss: 0.2925\n","Epoch 190/200\n","188/188 [==============================] - 200s 1s/step - loss: 0.4402 - accuracy: 0.9128 - val_loss: 0.2807 - val_accuracy: 0.9690 - lr: 0.0010\n","Accuracy: 0.9128 | Loss: 0.4402 | Val Accuracy: 0.9690 | Val Loss: 0.2807\n","Epoch 191/200\n","188/188 [==============================] - 214s 1s/step - loss: 0.4707 - accuracy: 0.9060 - val_loss: 0.2837 - val_accuracy: 0.9754 - lr: 0.0010\n","Accuracy: 0.9060 | Loss: 0.4707 | Val Accuracy: 0.9754 | Val Loss: 0.2837\n","Epoch 192/200\n","188/188 [==============================] - 201s 1s/step - loss: 0.4514 - accuracy: 0.9111 - val_loss: 0.2869 - val_accuracy: 0.9706 - lr: 0.0010\n","Accuracy: 0.9111 | Loss: 0.4514 | Val Accuracy: 0.9706 | Val Loss: 0.2869\n","Epoch 193/200\n","188/188 [==============================] - 216s 1s/step - loss: 0.4444 - accuracy: 0.9156 - val_loss: 0.2730 - val_accuracy: 0.9770 - lr: 0.0010\n","Accuracy: 0.9156 | Loss: 0.4444 | Val Accuracy: 0.9770 | Val Loss: 0.2730\n","Epoch 194/200\n","188/188 [==============================] - 195s 1s/step - loss: 0.4425 - accuracy: 0.9178 - val_loss: 0.2711 - val_accuracy: 0.9714 - lr: 0.0010\n","Accuracy: 0.9178 | Loss: 0.4425 | Val Accuracy: 0.9714 | Val Loss: 0.2711\n","Epoch 195/200\n","188/188 [==============================] - 209s 1s/step - loss: 0.4384 - accuracy: 0.9190 - val_loss: 0.2754 - val_accuracy: 0.9778 - lr: 0.0010\n","Accuracy: 0.9190 | Loss: 0.4384 | Val Accuracy: 0.9778 | Val Loss: 0.2754\n","Epoch 196/200\n","188/188 [==============================] - 206s 1s/step - loss: 0.4486 - accuracy: 0.9161 - val_loss: 0.3042 - val_accuracy: 0.9643 - lr: 0.0010\n","Accuracy: 0.9161 | Loss: 0.4486 | Val Accuracy: 0.9643 | Val Loss: 0.3042\n","Epoch 197/200\n","188/188 [==============================] - 201s 1s/step - loss: 0.4471 - accuracy: 0.9110 - val_loss: 0.2735 - val_accuracy: 0.9810 - lr: 0.0010\n","Accuracy: 0.9110 | Loss: 0.4471 | Val Accuracy: 0.9810 | Val Loss: 0.2735\n","Epoch 198/200\n","188/188 [==============================] - 205s 1s/step - loss: 0.4995 - accuracy: 0.8985 - val_loss: 0.2954 - val_accuracy: 0.9722 - lr: 0.0010\n","Accuracy: 0.8985 | Loss: 0.4995 | Val Accuracy: 0.9722 | Val Loss: 0.2954\n","Epoch 199/200\n","188/188 [==============================] - 200s 1s/step - loss: 0.4536 - accuracy: 0.9143 - val_loss: 0.3460 - val_accuracy: 0.9563 - lr: 0.0010\n","Accuracy: 0.9143 | Loss: 0.4536 | Val Accuracy: 0.9563 | Val Loss: 0.3460\n","Epoch 200/200\n","188/188 [==============================] - 199s 1s/step - loss: 0.4197 - accuracy: 0.9238 - val_loss: 0.2664 - val_accuracy: 0.9762 - lr: 0.0010\n","Accuracy: 0.9238 | Loss: 0.4197 | Val Accuracy: 0.9762 | Val Loss: 0.2664\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Conv2D, Activation, BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.utils import get_custom_objects\n","\n","# Define a learning rate schedule\n","def learning_rate_schedule(epoch, lr):\n","    if epoch < 20:\n","        return lr\n","    elif epoch < 40:\n","        return lr * 0.5\n","    else:\n","        return lr * 0.1\n","\n","# Define the Monte Carlo Dropout layer\n","class MonteCarloDropout(Dropout):\n","    def dropped_inputs(self, inputs, training=None):\n","        return super().call(inputs, training=training)\n","\n","# Register the custom layer\n","get_custom_objects()['MonteCarloDropout'] = MonteCarloDropout\n","\n","weight_decay = 1e-5\n","\n","model = Sequential()\n","\n","model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=(64, 64, 1)))\n","model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Activation('relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(MonteCarloDropout(0.2))\n","\n","model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=(64, 64, 1)))\n","model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Activation('relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.2))\n","model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=(64, 64, 1)))\n","model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Activation('relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.3))\n","\n","model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Activation('relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(MonteCarloDropout(0.3))\n","\n","\n","model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Activation('relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.4))\n","\n","model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Activation('relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.5))\n","\n","model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Activation('relu'))\n","model.add(BatchNormalization())\n","model.add(MonteCarloDropout(0.4))\n","\n","model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Activation('relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.6))\n","\n","model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","model.add(Activation('relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.6))\n","\n","model.add(Flatten())\n","model.add(Dense(256, activation=\"relu\"))\n","model.add(BatchNormalization())\n","model.add(Dense(512, activation=\"relu\"))\n","model.add(BatchNormalization())\n","model.add(Dense(10, activation='softmax'))\n","\n","\n","# Use the learning rate scheduler with the Adam optimizer\n","optimizer = Adam(learning_rate=0.001)\n","model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Define the learning rate adjustment callback\n","lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)\n","\n","# Use the learning rate scheduler callback and learning rate adjustment callback during training\n","callbacks = [LearningRateScheduler(learning_rate_schedule), lr_reducer]\n","\n","# Train the model\n","epochs = 200\n","for epoch in range(epochs):\n","    print(f\"Epoch {epoch+1}/{epochs}\")\n","    history = model.fit(training_set,\n","                        epochs=1,\n","                        steps_per_epoch=len(training_set),\n","                        validation_data=test_set,\n","                        validation_steps=len(test_set),\n","                        callbacks=callbacks,\n","                        verbose=1)\n","\n","    # Access the accuracy and loss for each epoch\n","    accuracy = history.history['accuracy'][0]\n","    loss = history.history['loss'][0]\n","    val_accuracy = history.history['val_accuracy'][0]\n","    val_loss = history.history['val_loss'][0]\n","\n","    print(f\"Accuracy: {accuracy:.4f} | Loss: {loss:.4f} | Val Accuracy: {val_accuracy:.4f} | Val Loss: {val_loss:.4f}\")\n","\n","# Save the trained model\n","model.save('modelweightbalanceddata.h5')\n"]},{"cell_type":"code","execution_count":null,"id":"b1731901","metadata":{"id":"b1731901"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","import numpy as np\n","from tensorflow.keras.models import load_model\n"]},{"cell_type":"code","execution_count":null,"id":"a319d8c3","metadata":{"id":"a319d8c3"},"outputs":[],"source":["# Make predictions on the test set\n","predictions = model.predict(test_set)\n","\n","# Convert the predictions into class labels\n","predicted_labels = np.argmax(predictions, axis=1)\n","\n","# Get the true labels from the test set\n","true_labels = test_set.labels\n","\n","# Calculate the confusion matrix\n","conf_matrix = confusion_matrix(true_labels, predicted_labels)\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":5}